#!/usr/bin/env python3
"""
LLMå¢å¼ºåŠŸèƒ½å®Œæ•´æ¼”ç¤ºè„šæœ¬
å±•ç¤ºLlama3.2é›†æˆåçš„æ™ºèƒ½æŸ¥è¯¢èƒ½åŠ›
"""

import asyncio
import json
import requests
import time
from typing import Dict, Any, List
from datetime import datetime

class LLMQueryDemo:
    """LLMæŸ¥è¯¢æ¼”ç¤ºç±»"""
    
    def __init__(self, api_base: str = "http://localhost:8000"):
        self.api_base = api_base
        self.session = requests.Session()
        
    def print_header(self, title: str):
        """æ‰“å°æ ‡é¢˜"""
        print(f"\n{'='*60}")
        print(f"  {title}")
        print(f"{'='*60}")
    
    def print_section(self, title: str):
        """æ‰“å°èŠ‚æ ‡é¢˜"""
        print(f"\n{'-'*50}")
        print(f"  {title}")
        print(f"{'-'*50}")
    
    def check_llm_status(self) -> Dict[str, Any]:
        """æ£€æŸ¥LLMæœåŠ¡çŠ¶æ€"""
        try:
            response = self.session.get(f"{self.api_base}/api/v1/llm-query/llm-status")
            return response.json()
        except Exception as e:
            return {"status": "error", "error": str(e)}
    
    def llm_query(self, query: str, detailed: bool = False) -> Dict[str, Any]:
        """æ‰§è¡ŒLLMå¢å¼ºæŸ¥è¯¢"""
        payload = {
            "query": query,
            "use_llm": True,
            "detailed_response": detailed
        }
        
        start_time = time.time()
        try:
            response = self.session.post(
                f"{self.api_base}/api/v1/llm-query/ask",
                json=payload,
                timeout=120
            )
            result = response.json()
            result["_response_time"] = time.time() - start_time
            return result
        except Exception as e:
            return {
                "status": "error",
                "error": str(e),
                "_response_time": time.time() - start_time
            }
    
    def complex_query(self, query: str) -> Dict[str, Any]:
        """æ‰§è¡Œå¤æ‚æŸ¥è¯¢"""
        payload = {"query": query}
        
        try:
            response = self.session.post(
                f"{self.api_base}/api/v1/llm-query/complex-query",
                json=payload,
                timeout=120
            )
            return response.json()
        except Exception as e:
            return {"status": "error", "error": str(e)}
    
    def batch_query(self, queries: List[str]) -> Dict[str, Any]:
        """æ‰§è¡Œæ‰¹é‡æŸ¥è¯¢"""
        payload = {"queries": queries}
        
        try:
            response = self.session.post(
                f"{self.api_base}/api/v1/llm-query/batch-process",
                json=payload,
                timeout=300
            )
            return response.json()
        except Exception as e:
            return {"status": "error", "error": str(e)}
    
    def demonstrate_basic_queries(self):
        """æ¼”ç¤ºåŸºæœ¬LLMå¢å¼ºæŸ¥è¯¢"""
        self.print_header("LLMå¢å¼ºåŸºæœ¬æŸ¥è¯¢æ¼”ç¤º")
        
        basic_queries = [
            {
                "query": "å¸®æˆ‘æ‰¾æ‰¾é²è¿…å†™çš„å°è¯´ä½œå“ï¼Œæœ€å¥½æ˜¯æ¯”è¾ƒæœ‰åçš„é‚£ç§",
                "description": "å¤æ‚ä½œè€…æŸ¥è¯¢ + è¯­ä¹‰ç†è§£"
            },
            {
                "query": "æœ‰æ²¡æœ‰é€‚åˆåˆå­¦è€…çš„Pythonç¼–ç¨‹ä¹¦ç±ï¼Ÿ",
                "description": "æ¡ä»¶ç­›é€‰ + è¯­ä¹‰åŒ¹é…"
            },
            {
                "query": "å¼ ä¸‰è¿™ä¸ªæœˆå€Ÿäº†å“ªäº›ä¹¦ï¼Ÿéƒ½æ˜¯ä»€ä¹ˆç±»å‹çš„ï¼Ÿ",
                "description": "å­¦ç”ŸæŸ¥è¯¢ + æ—¶é—´èŒƒå›´ + åˆ†ç±»ä¿¡æ¯"
            },
            {
                "query": "æœ€è¿‘å“ªäº›å›¾ä¹¦æ¯”è¾ƒçƒ­é—¨ï¼Ÿç»Ÿè®¡ä¸€ä¸‹å€Ÿé˜…æƒ…å†µ",
                "description": "ç»Ÿè®¡åˆ†æ + æ—¶é—´æ„ŸçŸ¥"
            }
        ]
        
        for i, item in enumerate(basic_queries, 1):
            self.print_section(f"æ¼”ç¤º {i}: {item['description']}")
            print(f"ç”¨æˆ·è¾“å…¥: \"{item['query']}\"")
            
            result = self.llm_query(item['query'], detailed=True)
            
            print(f"å¤„ç†æ–¹æ³•: {result.get('processing_method', 'unknown')}")
            print(f"å“åº”æ—¶é—´: {result.get('_response_time', 0):.2f}s")
            print(f"è¯†åˆ«æ„å›¾: {result.get('intent', 'unknown')}")
            print(f"ç½®ä¿¡åº¦: {result.get('nlu_confidence', 0):.2f}")
            
            if result.get('status') == 'success':
                print(f"è‡ªç„¶è¯­è¨€å“åº”: {result.get('natural_response', '')}")
                print(f"ç»“æœæ•°é‡: {result.get('result_count', 0)}")
                
                if result.get('suggestions'):
                    print("æ™ºèƒ½å»ºè®®:")
                    for suggestion in result['suggestions'][:3]:
                        print(f"  â€¢ {suggestion}")
            else:
                print(f"å¤„ç†çŠ¶æ€: {result.get('status')}")
                if result.get('error_message'):
                    print(f"é”™è¯¯ä¿¡æ¯: {result['error_message']}")
            
            time.sleep(1)  # é¿å…è¯·æ±‚è¿‡äºé¢‘ç¹
    
    def demonstrate_complex_queries(self):
        """æ¼”ç¤ºå¤æ‚æŸ¥è¯¢åŠŸèƒ½"""
        self.print_header("å¤æ‚æŸ¥è¯¢åˆ†ææ¼”ç¤º")
        
        complex_queries = [
            {
                "query": "ç»Ÿè®¡æœ¬æœˆå€Ÿé˜…é‡æœ€é«˜çš„ç§‘æŠ€ç±»å›¾ä¹¦ï¼ŒåŒæ—¶æ˜¾ç¤ºè¿™äº›ä¹¦çš„ä½œè€…ä¿¡æ¯å’Œå½“å‰åº“å­˜çŠ¶æ€",
                "description": "å¤šè¡¨å…³è” + ç»Ÿè®¡åˆ†æ + æ¡ä»¶ç­›é€‰"
            },
            {
                "query": "æŸ¥è¯¢ä»Šå¹´æ–°å¢çš„å›¾ä¹¦ä¸­ï¼Œå“ªäº›è¿˜æ²¡æœ‰è¢«ä»»ä½•å­¦ç”Ÿå€Ÿé˜…è¿‡ï¼ŒæŒ‰ç±»åˆ«åˆ†ç»„æ˜¾ç¤º",
                "description": "æ—¶é—´ç­›é€‰ + åå‘æŸ¥è¯¢ + åˆ†ç»„ç»Ÿè®¡"
            },
            {
                "query": "åˆ†æä¸€ä¸‹è®¡ç®—æœºä¸“ä¸šå­¦ç”Ÿçš„å€Ÿé˜…åå¥½ï¼Œçœ‹çœ‹ä»–ä»¬æœ€å–œæ¬¢å€Ÿä»€ä¹ˆç±»å‹çš„ä¹¦",
                "description": "ç”¨æˆ·ç”»åƒåˆ†æ + åå¥½ç»Ÿè®¡"
            }
        ]
        
        for i, item in enumerate(complex_queries, 1):
            self.print_section(f"å¤æ‚æŸ¥è¯¢ {i}: {item['description']}")
            print(f"ç”¨æˆ·è¾“å…¥: \"{item['query']}\"")
            
            result = self.complex_query(item['query'])
            
            print(f"æ„å›¾ç†è§£: {result.get('interpreted_intent', 'æœªçŸ¥')}")
            print(f"ç½®ä¿¡åº¦: {result.get('confidence', 0):.2f}")
            
            if result.get('status') == 'success':
                print(f"æŸ¥è¯¢è§£é‡Š: {result.get('explanation', '')}")
                print(f"ç»“æœæ•°é‡: {result.get('result_count', 0)}")
                
                if result.get('sql_query'):
                    sql_preview = result['sql_query'][:150] + "..." if len(result['sql_query']) > 150 else result['sql_query']
                    print(f"ç”ŸæˆSQL: {sql_preview}")
                
                if result.get('assumptions'):
                    print("æŸ¥è¯¢å‡è®¾:")
                    for assumption in result['assumptions']:
                        print(f"  â€¢ {assumption}")
                        
            else:
                print(f"å¤„ç†çŠ¶æ€: {result.get('status')}")
                if result.get('error'):
                    print(f"é”™è¯¯ä¿¡æ¯: {result['error']}")
            
            time.sleep(2)
    
    def demonstrate_batch_processing(self):
        """æ¼”ç¤ºæ‰¹é‡å¤„ç†åŠŸèƒ½"""
        self.print_header("æ‰¹é‡æŸ¥è¯¢å¤„ç†æ¼”ç¤º")
        
        batch_queries = [
            "æŸ¥æ‰¾ã€Šä¸‰å›½æ¼”ä¹‰ã€‹",
            "é²è¿…çš„ä½œå“æœ‰å“ªäº›ï¼Ÿ",
            "è®¡ç®—æœºç±»åˆ«çš„ä¹¦ç±",
            "æœ€çƒ­é—¨çš„5æœ¬ä¹¦",
            "æœ‰å“ªäº›é€¾æœŸçš„ä¹¦ï¼Ÿ"
        ]
        
        print("æ‰¹é‡æŸ¥è¯¢åˆ—è¡¨:")
        for i, query in enumerate(batch_queries, 1):
            print(f"  {i}. {query}")
        
        print("\nå¼€å§‹æ‰¹é‡å¤„ç†...")
        start_time = time.time()
        
        result = self.batch_query(batch_queries)
        
        processing_time = time.time() - start_time
        print(f"æ‰¹é‡å¤„ç†å®Œæˆï¼Œè€—æ—¶: {processing_time:.2f}s")
        print(f"å¤„ç†çŠ¶æ€: {result.get('status')}")
        print(f"å¤„ç†æ•°é‡: {result.get('processed_count', 0)}")
        
        if result.get('results'):
            success_count = sum(1 for r in result['results'] if r.get('result', {}).get('status') == 'success')
            print(f"æˆåŠŸå¤„ç†: {success_count}/{len(result['results'])}")
            
            print("\næ‰¹é‡ç»“æœæ‘˜è¦:")
            for i, item in enumerate(result['results'], 1):
                query = item['query']
                status = item.get('result', {}).get('status', 'unknown')
                
                if status == 'success':
                    result_count = item['result'].get('result_count', 0)
                    natural_response = item['result'].get('natural_response', '')[:50] + "..."
                    print(f"  {i}. {query} -> âœ… {result_count}æ¡ç»“æœ")
                    print(f"     {natural_response}")
                else:
                    error = item.get('error', 'unknown error')
                    print(f"  {i}. {query} -> âŒ {error}")
    
    def demonstrate_comparison(self):
        """æ¼”ç¤ºLLM vs è§„åˆ™ç³»ç»Ÿå¯¹æ¯”"""
        self.print_header("LLMå¢å¼º vs è§„åˆ™ç³»ç»Ÿå¯¹æ¯”")
        
        comparison_queries = [
            "æ‰¾æ‰¾é‚£äº›é€‚åˆè®¡ç®—æœºä¸“ä¸šå­¦ç”Ÿçœ‹çš„ç¼–ç¨‹å…¥é—¨ä¹¦ç±",
            "è¿™ä¸ªæœˆå­¦ç”Ÿä»¬æœ€çˆ±å€Ÿçš„éƒ½æ˜¯ä»€ä¹ˆç±»å‹çš„ä¹¦ï¼Ÿ",
            "æœ‰æ²¡æœ‰é‚£ç§è®²äººå·¥æ™ºèƒ½åŸºç¡€çŸ¥è¯†çš„ä¹¦ï¼Œä¸è¦å¤ªéš¾çš„"
        ]
        
        for i, query in enumerate(comparison_queries, 1):
            self.print_section(f"å¯¹æ¯”æŸ¥è¯¢ {i}")
            print(f"æŸ¥è¯¢: \"{query}\"")
            
            # LLMå¢å¼ºæŸ¥è¯¢
            print("\nğŸ¤– LLMå¢å¼ºå¤„ç†:")
            llm_result = self.llm_query(query)
            print(f"  çŠ¶æ€: {llm_result.get('status')}")
            print(f"  æ„å›¾: {llm_result.get('intent', 'unknown')}")
            print(f"  ç½®ä¿¡åº¦: {llm_result.get('nlu_confidence', 0):.2f}")
            print(f"  å“åº”: {llm_result.get('natural_response', 'N/A')}")
            
            # è§„åˆ™ç³»ç»ŸæŸ¥è¯¢ï¼ˆæ¨¡æ‹Ÿï¼‰
            print("\nğŸ“‹ è§„åˆ™ç³»ç»Ÿå¤„ç†:")
            rule_result = self.llm_query(query.replace("é€‚åˆ", "").replace("å…¥é—¨", "").replace("åŸºç¡€çŸ¥è¯†", ""))
            print(f"  çŠ¶æ€: {rule_result.get('status')}")
            print(f"  æ„å›¾: {rule_result.get('intent', 'unknown')}")
            print(f"  å“åº”: åŸºç¡€å…³é”®è¯åŒ¹é…æŸ¥è¯¢")
            
            time.sleep(1)
    
    def demonstrate_capabilities(self):
        """æ¼”ç¤ºç³»ç»Ÿèƒ½åŠ›"""
        self.print_header("ç³»ç»Ÿèƒ½åŠ›å±•ç¤º")
        
        try:
            response = self.session.get(f"{self.api_base}/api/v1/llm-query/capabilities")
            capabilities = response.json()
            
            print("ğŸš€ LLMå¢å¼ºåŠŸèƒ½:")
            for feature in capabilities.get('enhanced_features', []):
                print(f"  â€¢ {feature['name']}: {feature['description']}")
                if feature.get('examples'):
                    print(f"    ç¤ºä¾‹: {feature['examples'][0]}")
            
            print(f"\nğŸ“Š æ”¯æŒçš„æŸ¥è¯¢ç±»å‹:")
            for query_type in capabilities.get('supported_query_types', []):
                print(f"  â€¢ {query_type}")
            
            print(f"\nâš¡ æ€§èƒ½ç‰¹æ€§:")
            for perf_feature in capabilities.get('performance_features', []):
                print(f"  â€¢ {perf_feature}")
            
            print(f"\nâš ï¸ ä½¿ç”¨é™åˆ¶:")
            for limitation in capabilities.get('limitations', []):
                print(f"  â€¢ {limitation}")
                
        except Exception as e:
            print(f"è·å–èƒ½åŠ›ä¿¡æ¯å¤±è´¥: {e}")
    
    def run_demo(self):
        """è¿è¡Œå®Œæ•´æ¼”ç¤º"""
        print("ğŸ¯ SmartLib LLMå¢å¼ºåŠŸèƒ½å®Œæ•´æ¼”ç¤º")
        print(f"æ¼”ç¤ºæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        
        # æ£€æŸ¥æœåŠ¡çŠ¶æ€
        self.print_header("æœåŠ¡çŠ¶æ€æ£€æŸ¥")
        status = self.check_llm_status()
        print(f"LLMæœåŠ¡çŠ¶æ€: {status.get('status')}")
        
        if status.get('status') == 'healthy':
            print("âœ… æ‰€æœ‰æœåŠ¡æ­£å¸¸è¿è¡Œ")
            
            # è¿è¡Œå„ç§æ¼”ç¤º
            self.demonstrate_basic_queries()
            self.demonstrate_complex_queries()
            self.demonstrate_batch_processing()
            self.demonstrate_comparison()
            self.demonstrate_capabilities()
            
            # æ¼”ç¤ºæ€»ç»“
            self.print_header("æ¼”ç¤ºæ€»ç»“")
            print("ğŸ‰ LLMå¢å¼ºåŠŸèƒ½æ¼”ç¤ºå®Œæˆ!")
            print("\nä¸»è¦ä¼˜åŠ¿:")
            print("  â€¢ ç†è§£å¤æ‚ã€æ¨¡ç³Šçš„è‡ªç„¶è¯­è¨€æŸ¥è¯¢")
            print("  â€¢ æ™ºèƒ½ç”Ÿæˆä¼˜åŒ–çš„SQLæŸ¥è¯¢")
            print("  â€¢ æä¾›è‡ªç„¶è¯­è¨€çš„ç»“æœè§£é‡Š")
            print("  â€¢ æ”¯æŒä¸Šä¸‹æ–‡æ„ŸçŸ¥çš„æŸ¥è¯¢å¤„ç†")
            print("  â€¢ å…·å¤‡é™çº§ä¿æŠ¤æœºåˆ¶")
            
            print(f"\néƒ¨ç½²è¯´æ˜:")
            print("  1. ç¡®ä¿OllamaæœåŠ¡è¿è¡Œåœ¨ localhost:11434")
            print("  2. ç¡®ä¿å·²å®‰è£…å¹¶ä¸‹è½½ llama3.2 æ¨¡å‹")
            print("  3. å¯åŠ¨SmartLib APIæœåŠ¡")
            print("  4. ä½¿ç”¨ /api/v1/llm-query/ask æ¥å£è¿›è¡ŒæŸ¥è¯¢")
            
        else:
            print("âŒ LLMæœåŠ¡ä¸å¯ç”¨")
            if status.get('error'):
                print(f"é”™è¯¯ä¿¡æ¯: {status['error']}")
            print("\nè¯·æ£€æŸ¥:")
            print("  1. Ollamaæ˜¯å¦å·²å¯åŠ¨: ollama serve")
            print("  2. Llama3.2æ˜¯å¦å·²å®‰è£…: ollama pull llama3.2")
            print("  3. ç½‘ç»œè¿æ¥æ˜¯å¦æ­£å¸¸")

def main():
    """ä¸»å‡½æ•°"""
    demo = LLMQueryDemo()
    
    try:
        demo.run_demo()
    except KeyboardInterrupt:
        print("\næ¼”ç¤ºè¢«ç”¨æˆ·ä¸­æ–­")
    except Exception as e:
        print(f"\næ¼”ç¤ºè¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
        print("è¯·æ£€æŸ¥æœåŠ¡æ˜¯å¦æ­£å¸¸è¿è¡Œ")

if __name__ == "__main__":
    main()
